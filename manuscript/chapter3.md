# Capacidades operacionales de un entorno DevOps
¿Cuáles son algunas de las capacidades que necesita implementar en un entorno DevOps? 

## Creación automatizada del entorno
En primer lugar, y posiblemente, antes que cualquier otra cosa, necesita capacidad de alistar entornos automáticamente y constantemente. Es una tarea fundamental pero no es fácil.

* Automáticamente: Significa permitir a una variedad de roles autorizados dentro de su organización configurar entornos bajo demanda, sin involucrar a ningún ser humano. Esto podría ser un entorno para desarrollo o un entorno de pruebas, y probablemente sea algo que necesitan hacer varias veces al día. También podría ser un proceso automatizado alistando un entorno en el que ejecutar pruebas de aceptación.

* De manera consistente: Los entornos que se “crean” deben reflejar con precisión el entorno de producción final. Hay dos formas de hacerlo:
  * Definir un método de creación de entornos, y utilizarlo para crear el entorno de producción, así como cualquier otro entorno cuando sea necesario. De esa manera, sabrá que todos los entornos coinciden.
  * Modelar un entorno a partir del entorno de producción. A continuación, puede aplicar ese modelo a cualquier otro entorno que necesite alistar.

Tecnologías de gestión de configuración emergentes, como DSC de Microsoft, o productos como Chef, Salt, Puppet y Ansible, son ejemplos de herramientas que ayudan a implementar algunas de estas capacidades. Cuando puede escribir algún tipo de documento de configuración que describe el entorno y, a continuación, tiene una herramienta que puede implementar ese documento donde y cuando quiera, se estará acercando a la capacidad necesaria. Los containers son otra tecnología que puede ayudar en este espacio, ya que le permite abstraerse de una serie de variables, reduciendo la transformación y complejidad.

Es fácil entender por qué esta es una capacidad tan importante. Si puede garantizar que todo lo que una aplicación puede ejecutar (desarrollo, prueba o producción) es exactamente el mismo, todo el tiempo, entonces es mucho menos probable que tenga problemas para mover el código de un entorno a otro. Además, al ofrecer a otros roles, como los desarrolladores, la capacidad de generar estos entornos bajo demanda, ayuda a facilitar más pruebas en el mundo real y elimina más problemas durante la fase de desarrollo.

No quiero minimizar la dificultad de crear esta capacidad, ni tampoco ocultar los problemas que esto trae a la gestión. Los entornos requieren de recursos para funcionar, por lo tanto, las organizaciones pueden estar justificadamente preocupadas por permitir a los desarrolladores “crear” máquinas virtuales a su antojo. Pero _no estamos hablando de capacidades sin gestión alguna_. Eso es algo que me mata cada vez que entro en una discusión sobre DevOps con ciertos tipos de organizaciones. "¡Bueno, una vez que demos a los desarrolladores permisos para crear las máquinas virtuales que quieran, será el fin del mundo!" Y de esta forma presienten una derrota temprana. Pero eso no es de lo que estamos hablando.

La razón por la que DevOps tiene "Ops" al final, es porque _Operaciones no desaparece_. Los desarrolladores no "toman el control". Nuestro trabajo es proporcionar a los desarrolladores un _conjunto gestionado de capacidades_. Así que sí, un desarrollador que trabaja en un proyecto debe ser capaz de “montar” una máquina virtual sin la intervención de nadie, también de ser capaz de reciclarla, es decir, eliminar y volver a crear ese entorno en el momento que se requiera. Pero eso no significa que pueda llegar a cambiar la especificación del entorno por sí mismo, ni tampoco significa que obtendrá un dominio libre de la infraestructura de virtualización. No.

Permítanme ofrecer un ejemplo realmente simplista, pero increíblemente real, de lo que estamos hablando. El servicio Elastic Beanstalk de Amazon está diseñado para crear nuevos entornos, es decir, máquinas virtuales, más o menos a la carta, en respuesta a la carga del cliente. Cada nueva máquina virtual se inicia como una copia idéntica de una imagen del sistema operativo base y cada nueva máquina virtual puede cargar contenido, como un sitio web, desde un repositorio de GitHub. Así que ahí mismo, ha creado algo de la automatización y la coherencia que necesita. Con un “botón de inicio”, o en reacción a la carga del usuario, se puede automatizar la creación de nuevos entornos, y como todos provienen de fuentes conocidas estándar, este entorno será coherente..

Es muy probable que los desarrolladores necesiten cambios más allá de lo que hay en la imagen de base del sistema operativo, por lo que estos deben poder especificar elementos adicionales. Pueden establecer variables de entorno, especificar paquetes para descargar e instalar, y así sucesivamente. En el pasado, un desarrollador habría manipulado su entorno de desarrollo hasta que todo funcione, y luego con suerte comunicar los resultados de esa manipulación a alguien en de Operaciones. Ops entonces, con suerte, volvería a crear fielmente lo que el desarrollador hizo. ¿Pero se obtuvieron las versiones correctas de los paquetes? ¿Se configuraron todas las variables de entorno?

Sin embargo, en Elastic Beanstalk, los desarrolladores no sólo "modifican" el entorno. Eso es porque cada vez que una máquina virtual se apaga, se desvanece. Cualquier retoque que se haga se pierde. En el siguiente inicio, se vuelve a la imagen del sistema operativo base. Por lo tanto, como parte del origen del proyecto en GitHub, los desarrolladores pueden especificar un archivo de configuración que enumera explícitamente todos los paquetes adicionales, la configuración del entorno o lo que sea que necesiten. Dado que esa información de configuración forma parte de la fuente GitHub, cada nueva VM creada por Elastic Beanstalk se creará con la misma configuración exacta, cada vez.

Este es un enfoque muy DevOps, y en este caso, Amazon ha asumido el papel de "Ops". Si un desarrollador quiere hacer un cambio ambiental, modifica la fuente del proyecto y luego le dice a Amazon que recicle el ambiente. Todo se apaga, y un ambiente nuevo y fresco se libera. Está completamente documentado, así que, si funciona de la manera que el dev quiere, entonces será perfecto cuando se usa para pruebas, producción o cualquier otra cosa. Y, de una manera típica centrada en la nube, Ops, es decir, Amazon, no tiene que involucrarse de ninguna manera. Han creado interfaces de automatización que permiten a cualquier usuario autorizado modificar lo que quiera.

Como una barra lateral, esta idea de DevOps es una especie de seguimiento del concepto de "nube privada". Nube privada significa simplemente ejecutar sus recursos de TI privados de una manera similar a los proveedores de una nube pública, lo que implica la automatización en el lado de Operaciones. Se basa en una forma de especificar quién puede hacer qué, y luego dejar que lo haga por su cuenta. Con un proveedor de Cloud público, los permisos consisten más o menos en "lo que se paga", pero en una situación de nube privada, los permisos pueden ser mucho más granulares o incluso completamente diferentes. Nadie sugiere que construya su propio AWS o Azure. Eso no es lo que significa nube privada. Sin embargo, verá que las capacidades de la nube privada son las mismas que debe proporcionar como persona de Operaciones, para habilitar un enfoque de DevOps dentro de su organización.

## Infraestructura de desarrollo y pruebas
Como describí en el capítulo anterior, la administración de TI tradicional coloca algunas "puertas" bastante firmes entre desarrollo, pruebas y, especialmente, Operaciones. "Operaciones" es más o menos un sinónimo de "producción". En DevOps, rompemos esa relación y eliminamos las puertas. Operaciones es responsable de la infraestructura, ya sea que la infraestructura se para soporte de desarrollo, de pruebas o a los usuarios de producción. Y esas diferentes fases del ciclo de vida de la aplicación se integran mucho más estrechamente en DevOps. Algunas de las cosas de alto nivel que necesitará son:

* Repositorios de código fuente. Git es un ejemplo común en estos días, al igual que Microsoft Team Foundation Server y algunos otros. Lo importante es que las herramientas de sus desarrolladores estén estrechamente integradas con lo que haya elegido. Idealmente, estos repositorios deberían tener, o ser capaces de integrarse con, algún tipo de “codificación avanzada”. Por ejemplo, el repositorio debería ser capaz de ejecutar pruebas predefinidas en el propio código antes de permitir el registro de cambios, y podría realizar una rutina automatizada de compilación y pruebas cada vez que se “detecte” código nuevo o cambios en el mismo.

* Tableros de instrumentos. Los desarrolladores y probadores necesitan tener acceso a las capacidades operativas que les han proporcionado, como la de reciclar un entorno de desarrollo virtual. Idealmente, se puede integrar esto como parte de su herramienta de gestión principal, o como un entorno de desarrollo integrado. Ser capaz de hacer clic en un botón para "compilar eso, preparar un entorno de desarrollo, cargar el código compilado y ejecutar la aplicación" es bastante potente. En los casos en que ese nivel de integración no sea posible, entonces necesitará proporcionar alguna otra interfaz para hacer que algunas de esas actividades sean fáciles de llevar a cabo.

* Herramientas de prueba. Una cierta cantidad de pruebas tiene que ser automatizada, para que los desarrolladores pueden obtener retroalimentación inmediata, y para que las pruebas se pueden ejecutar de la manera más coherente posible.

That last capability is perhaps one of the most complex. In one ideal approach (although certainly not the only one, and even this will be a simplified example), the workflow might be something like this:

1. Developer writes code.
2. Developer runs code in a "private" development environment, performing unit tests.
3. Developer repeats steps 1-2 until they're satisfied with the code, and then checks it into a repository.
4. Repository runs certain quality checks - which might simply enforce things like coding conventions - before allowing check-in.
5. If check-in succeeds, repository kicks off an automated build of the code. This is deployed to a newly-created test environment.
6. Automated testing tools run a number of acceptance tests on the code. This might involve providing specific inputs to the application and then looking for specific outputs, "hacking" data into a database to test application response, or so on. Creating these tests is really a coding effort in and of itself, and it might be completed by the developer working on the code, or by a dedicated test coder.
7. Test results are stored - often in a part of the source code repository. 
8. If tests were successful, then the build is staged for deployment. Deployment might happen during a scheduled window following that build.

You can see that the human labor here is almost all on developers, which is one reason people refer to DevOps as a "software development methodology." But the Ops piece provides all the infrastructure and automation from step 4 on, enabling a successful build to move directly to production.

Obviously, different organizations will have different takes on this. Some might mandate user acceptance testing as an additional manual step, although Ops could help automate that. For example, after step 7 above, you might automate the creation of a user acceptance testing environment, deploy the code to that environment, and then notify someone that it's ready for testing. Their acceptance might trigger the stage-for-production step, or their rejection might feed back to the developer to begin again at step 1.

The point is that _Operations_ needs to provide the automation so that this sequence runs with as little _unnecessary_ manual intervention as possible. Certainly, _Ops_ should never be acting as a gatekeeper. We're not code testers. If the code passed whatever quality checkpoints have been defined, then the code's ready to deploy, and we should handle as much of that automatically as possible. Even the deployment - once approved, and on whatever schedule we've defined - should happen automatically.

You can see that DevOps, as an abstract philosophy, actually requires a lot of concrete tooling. And you can perhaps see that, because organizations will all have different particulars about how they want to manage the process, it would be difficult for commercial vendors to produce that tooling. There's not really a "one size fits all" approach for DevOps, which means Operations will end up creating a lot of it's _own_ tooling. That's where _platform_ technologies come into play. They can provide a set of building blocks that make it easier to create those custom DevOps tools you'll need.

## End-User Experience Monitoring
This is perhaps the most important part of a DevOps organization, and it's the easiest to overlook.

As an IT Ops person, you're probably already pretty familiar with monitoring, and make no mistake: it's just as important under DevOps as it was before DevOps. Monitoring not only to notify someone when something goes wrong, but also monitoring to help profile applications (and their supporting services and infrastructure), so you can proactively address problems before they become severe.

But IT Ops' definition of "monitoring" often isn't as inclusive as it should be. We tend to only monitoring _the things that are directly under our control._ We monitor network usage, processor load, and disk space. We monitor network latency, service response times, and server health. We monitor these things _because we can affect these things_. 

One of the biggest collaborations a DevOps organization can have, however, is monitoring _the end user experience_. It's something we, as IT people, can't directly touch, but if the whole point of IT is to deliver apps and services to users (and yes, that _is_ the whole point), then the end-user experience of those apps and services is quite literally _the only metric that matters_. Why do we measure network latency? Because it contributes to the user experience. Why do we measure service response time? User experience. We attempt to _indirectly_ measure the end-user experience, because we've often no way of _directly_ measuring it.

DevOps' philosophy of developers and operations collaborating comes to a pinnacle with end-user experience monitoring. Developers should build applications with the ability to track the end-user experience. For example, when some common operation is about to begin, the application should track the start time, and then track the end time. Any major steps in between should receive a timestamp, too, and that information should be logged someplace. In Operations, we need to provide a place for that log - that _performance artifact_ - to live, and we need to provide a way for developers to access it. We need to baseline what "normal" performance looks like, and monitor to track for declines in that baseline. Operations may be responsible for the monitoring itself, but developers, in their code, can give us the instrumentation to monitor what matters most. 

If end-user experience numbers begin to decline - say, the time it takes to perform a common query and display the results starts to get longer and longer - then we can dig into more detailed instrumentation and see if we can find the cause. Is it network latency? Server response time? Any other correlations that might point to a cause? But by directly measuring _what our users experience_, we have an unassailable top-level metric that represents the most real-world thing we can possibly have on the radar.

I'm making a big deal of end-user experience monitoring not only because it's important and useful, but also because it's one of the easiest-to-grasp examples of what DevOps is all about. Developers have traditionally _cared_ about users' experience (in theory), but they're extremely _disconnected_ from it. Operations is very connected to what users experience (we get the Help Desk calls, after all), but we're relatively powerless to put our fingers directly on it. Through the collaboration that drives DevOps philosophy, though, developers and operations personnel can come together to do their collective job better.


